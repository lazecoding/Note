# 大表优化

当系统里出现了千万级大表，很多人第一想法可能是各种切分，但这并不是合理的做法，切分应该是不得已而为之的做法，在切分之前我们应该努力一波。

### 存储引擎

选择正确的存储引擎是第一步。大部分情况下我们推荐 InnoDB 存储引擎，它在保持较好的查询性能的同时，具有较高写并发写入能力，而且提供事务支持。如果对于读多写少，而且不需要事务的表，我们可以考虑对表采用 MYISAM 存储引擎。MYISAM 不支持事务，减少了工作流程，保证了查询效率，但由于其表锁设计，并发写能力较差。

### 优化 SQL 和索引

优化 SQL 和索引，这并不是废话。也许有的人会说，开发阶段我已经进行了优化。但是往往优化的并不彻底，或者说随着业务扩展，原有索引需要重新调整。甚至有的只根据 SQL 去建索引，根本没对 SQL 本身进行优化。除了最简单的增删改查外，实现一个查询往往可以写出很多种语句，根据你选择的存储引擎、表中数据的分布、索引、数据库优化策略、查询中的锁策略等因素，最终查询的效率可能相差很大。而且即使精通 MySQL，除了纯技术角度的优化，还需要根据业务优化 SQL 语句（说不好还重构个业务，老熟练了...），这样才能达到最优效果。

### 缓存和消息队列

缓存如 Redis，消息队列如 RabbitMQ。面对千万级大表的查询请求，我们可以在业务层和持久层加一层缓存，避免每次都把请求打的 DB 上，使用缓存最直观的感受就是响应变快了。如果大表还拥有很多写入请求，由于数据量大，写入请求堆积也会导致 DB 响应变慢，我们可以引入消息队列，降低写入频率。

### 读写分离

到了这一步就需要考虑主从复制或主主复制，实现读写分离。可以在应用层做，效率高，但是侵入业务。也可以用通过中间件实现复制，对业务侵入较小，但遇到问题需要研究中间件，增加学习成本。为什么说通过中间件实现复制对业务侵入较小呢，因为读写分离，如果一条数据在写库数据同步到读库前被查询了，就无法被查询到。

### 分区

如果读写分离还是慢，也不要急着切分，尝试一下分区，再挣扎一下。

### 垂直切分

我们可以对一张大表垂直切分，如用户表切分位用户概况表和用户详情表。

### 水平切分

如果到了这一步，就只能进行水平切分了。尽可能不要将有关联的业务数据切分到不同分片上。

### 无可奈何

关系型数据库的瓶颈始终是个约束，是时候尝试 Elasticsearch 了。