# 日志存储

- 目录
    - [日志](#日志)
      - [LogSement](#LogSement)
      - [日志文件切分](#日志文件切分)
      - [索引文件切分](#索引文件切分)
    - [日志清理](#日志清理)
      - [日志删除](#日志删除)
        - [基于时间](#基于时间)
        - [基于日志大小](#基于日志大小)
        - [基于日志起始偏移量](#基于日志起始偏移量)
      - [日志压缩](#日志压缩)
        - [日志压缩的细节](#日志压缩的细节)
        - [配置 Log Cleaner](#配置-Log-Cleaner)
    - [磁盘存储](#磁盘存储)
      - [页缓存](#页缓存)
      - [零拷贝](#零拷贝)

主题和分区是 Kafka 的两个核心概念，主题作为消息的归类，可以再细分为一个或多个分区，分区也可以看作对消息的二次归类。分区的划分不仅为 Kafka 提供了可伸缩性、水平扩展的功能，还通过多副本机制来为 Kafka 提供数据冗余以提高数据可靠性。

从 Kafka 的底层实现来说，主题和分区都是逻辑上的概念，分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段（LogSegment），每个日志分段还可以细分为索引文件、日志存储文件和快照文件等。

主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是 Log 层面才有实际物理上的存在。同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。

更多介绍查看 [主题的分区和副本](https://github.com/lazecoding/Note/blob/main/note/articles/kafka/whatiskafka.md#主题的分区和副本) 。

### 日志

主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是 Log 层面才有实际物理上的存在。

> 此处说明的是 Kafka 消息存储的信息文件内容，不是所谓的 Kafka 服务器运行产生的日志文件。

考虑多副本的情况，一个分区对应一个日志 Log)。为了防止 Log 过大，Kafka 又引入了日志分段(LogSegment)的概念，将 Log 切分为多个 LogSegment，相当于一个巨型文件被平均分配为多个相对较小的文件。事实上， Log 和 LogSegment 也不是纯粹物理意义上的概念， Log 在物理上只以文件夹的形式存储，而在分区日志文件中，你会发现很多类型的文件，比如：.index、.timestamp、.log、.snapshot 等，其中，文件名一致的文件集合就称为 LogSement。

<div align="left">
    <img src="https://github.com/lazecoding/Note/blob/main/images/kafka/主题内部的日志实现结构.png" width="600px">
</div>

向 Log 中追加消息时是顺序写入的，只有最后一个 LogSegment 才能执行写入操作，在此之前所有的 LogSegment 都不能写入数据。

- 为了方便描述，我们将最后一个 LogSegment 称为 `activeSegment`，即表示当前活跃的日志分段。
- 随着消息的不断写入，当 `activeSegment` 满足一定的条件时，就需要创建新的 `activeSegment`，之后追加的消息将写入新的 `activeSegment`。

在某一时刻，Kafka 中的文件目录布局如图所示：

<div align="left">
    <img src="https://github.com/lazecoding/Note/blob/main/images/kafka/主题内部的日志文件目录.png" width="600px">
</div>

- 每一个根目录都会包含最基本的 4 个检查点文件(xxx-checkpoint)和 meta.properties 文件。
- 初始情况下主题 _consumer_offisets 并不存在，当第一次有消费者消费消息时会自动创建这个主题。
- 在创建主题的时候，如果当前 broker 中不止配置了一个根目录，那么会挑选分区数最少的那个根目录来完成本次创建任务。

#### LogSement

在分区日志文件中，你会发现很多类型的文件，比如：.index、.timestamp、.log、.snapshot 等，其中，文件名一致的文件集合就称为 LogSement。分区日志文件中包含很多的 LogSegment ，Kafka 日志追加是顺序写入的，LogSegment 可以减小日志文件的大小，进行日志删除的时候和数据查找的时候可以快速定位。同时，ActiveLogSegment 也就是活跃的日志分段拥有文件拥有写入权限，其余的 LogSegment 只有只读的权限。每个 LogSegment 都有一个基准偏移量，用来表示当前 LogSegment 中第一条消息的 offset。偏移量是一个 64 位的长整形数，固定是 20 位数字，长度未达到，用 0 进行填补，索引文件和日志文件都由该作为文件名命名规则。

日志文件中存在的多种后缀文件，重点需要关注 .index（偏移量索引文件）、.timestamp（时间戳索引文件）、.log（数据文件）三种类型。

- `偏移量索引文件（.log）`：用于记录消息偏移量与物理地址之间的映射关系。
- `时间戳索引文件（.timeindex）`：则根据时间戳查找对应的偏移量。
- `数据文件（.log）`：用于存储数据。

Kafka 中的索引文件是以稀疏索引的方式构造消息的索引，他并不保证每一个消息在索引文件中都有对应的索引项。每当写入一定量的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，通过修改 `log.index.interval.bytes` 的值，改变索引项的密度。

| 配置项 | 默认值 | 说明 |
| ----- | ---- | --- | 
| log.index.interval.bytes | 4096(4K) | 增加索引项字节间隔密度，会影响索引文件中的区间密度和查询效率 |
| log.segment.bytes | 1073741824(1G) | 日志文件最大值 |
| log.roll.ms | - | 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值允许的最大范围，毫秒维度 |
| log.roll.hours | 168(7天) | 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值允许的最大范围，小时维度 |
| log.index.size.max.bytes | 10485760(10MB) | 触发偏移量索引文件或时间戳索引文件分段字节限额 |

#### 日志文件切分

日志文件切分的规则如下，当满足如下几个条件中的其中之一，就会触发文件的切分：

- 当前日志分段文件的大小超过了 broker 端参数 `log.segment.bytes` 配置的值。`log.segment.bytes` 参数的默认值为 1073741824，即 1GB。
- 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 `log.roll.ms` 或 `log.roll.hours` 参数配置的值。如果同时配置了 `log.roll.ms` 和 `log.roll.hours` 参数，那么 `log.roll.ms` 的优先级高。默认情况下，只配置了 `log.roll.hours` 参数，其值为 168，即 7 天。
- 偏移量索引文件或时间戳索引文件的大小达到 broker 端参数 `log.index.size.max.bytes` 配置的值。`log.index.size.max.bytes` 的默认值为 10485760，即 10MB。
- 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于 Integer.MAX_VALUE，即要追加的消息的偏移量不能转变为相对偏移量。


为什么是 Integer.MAX_VALUE?在偏移量索引文件中，每个索引项共占用 8 个字节，并分为两部分：相对偏移量和物理地址。

- 相对偏移量：表示消息相对与基准偏移量的偏移量，占 4 个字节
- 物理地址：消息在日志分段文件中对应的物理位置，也占 4 个字节

4 个字节刚好对应 Integer.MAX_VALUE, 如果大于 Integer.MAX_VALUE, 则不能用 4 个字节进行表示了。

#### 索引文件切分

索引文件会根据 `log.index.size.max.bytes` 值进行预先分配空间，即文件创建的时候就是最大值，当真正的进行索引文件切分的时候，才会将其裁剪到实际数据大小的文件。这一点是跟日志文件有所区别的地方。其意义降低了代码逻辑的复杂性。

### 日志清理

日志清理，不是日志删除，这还是有所区别的。

Kafka 提供两种日志清理策略：

- `日志删除`：按照一定的删除策略，将不满足条件的数据进行数据删除。
- `日志压缩`：针对每个消息的 Key 进行整合，对于有相同 Key 的不同 Value 值，只保留最后一个版本。

Kafka 提供 `log.cleanup.policy` 参数进行相应配置，默认值：delete，还可以选择 compact。

是否支持针对具体的 Topic 进行配置？答案是肯定的，主题级别的配置项是 `cleanup.policy`。

#### 日志删除

Kafka 会周期性根据相应规则进行日志数据删除，保留策略有 3 种：

- 基于时间的保留策略。
- 基于日志大小的保留策略。
- 基于日志起始偏移量的保留策略。

##### 基于时间

日志删除任务会根据 `log.retention.hours`/`log.retention.minutes`/`log.retention.ms` 设定日志保留的时间节点。如果超过该设定值，就需要进行删除。默认是 7 天，`log.retention.ms` 优先级最高。

如何查找日志分段文件中已经过去的数据呢？Kafka 依据日志分段中最大的时间戳进行定位，首先要查询该日志分段所对应的时间戳索引文件，查找时间戳索引文件中最后一条索引项，若最后一条索引项的时间戳字段值大于 0，则取该值，否则取最近修改时间。

为什么不直接选最近修改时间呢？因为日志文件可以有意无意的被修改，并不能真实的反应日志分段的最大时间信息。

**删除过程**：

- 从日志对象中所维护日志分段的跳跃表中移除待删除的日志分段，保证没有线程对这些日志分段进行读取操作。
- 这些日志分段所有文件添加 上 .delete 后缀。
- 交由一个以 "delete-file" 命名的延迟任务来删除这些 .delete 为后缀的文件。
- 延迟执行时间可以通过 file.delete.delay.ms 进行设置

如果活跃的日志分段中也存在需要删除的数据时？Kafka 会先切分出一个新的日志分段作为活跃日志分段，然后执行删除操作。

##### 基于日志大小

日志删除任务会检查当前日志的大小是否超过设定值。设定项为 `log.retention.bytes`，单个日志分段的大小由 `log.regment.bytes` 进行设定。

**删除过程**：

- 计算需要被删除的日志总大小 (当前日志文件大小减去 retention 值)。
- 从日志文件第一个 LogSegment 开始查找可删除的日志分段的文件集合。
- 执行删除。


##### 基于日志起始偏移量

判断依据是某日志分段的下一个日志分段的起始偏移量是否大于等于日志文件的起始偏移量，若是，则可以删除此日志分段。

> 注意：日志文件的起始偏移量并不一定等于第一个日志分段的基准偏移量，存在数据删除，可能与之相等的那条数据已经被删除了。

**删除过程**：

- 从头开始变了每一个日志分段，日志分段 1 的下一个日志分段的起始偏移量为 11，小于 logStartOffset，将 日志分段 1 加入到删除队列中
- 日志分段 2 的下一个日志分段的起始偏移量为 23，小于 logStartOffset，将 日志分段 2 加入到删除队列中
- 日志分段 3 的下一个日志分段的起始偏移量为 30，大于 logStartOffset，则不进行删除。

#### 日志压缩

日志压缩确保 kafka 始终至少保留 topic 的分区数据中每条消息 key 的最后的值。它解决了一些用例和场景，如应用程序崩溃或系统故障后还原状态，或应用程序在运行维护过程中重新启动后重新加载缓存。这也意味着下游消费者可以获得最终的状态而无需拿到所有的变化的消息信息。

日志压缩是一种机制给每条细粒度的保留，而不是基于时间的粗粒度的保留，是有选择地删除记录，我们保留相同的主键的最新记录。这种方式的日志保证至少有每个 key 的最后状态。

下图是一个日志逻辑图，它展示了 Kafka 日志的每条消息的 offset 逻辑结构：

<div align="left">
    <img src="https://github.com/lazecoding/Note/blob/main/images/kafka/Kafka日志逻辑图.png" width="600px">
</div>

日志压缩增加了一个选项来处理尾部(tail)的日志，上图显示了一个尾部压缩日志。另外，日志尾部已分配的消息将保留原来的偏移量 —— 永远不会改变，还要注意，在日志中所有的偏移量仍然保持有效的位置，即使消息已经压缩，在这种情况下，在日志的下一个最高的 offset 的位置是无法区分的。例如，上图的偏移量 36，37 和 38 都是等效的位置，读这些 offset 都将返回消息集的开始位置 38。

压缩也允许删除。通过消息的 key 和空负载（null payload）来标识该消息可从日志中删除。这个删除标记将会引起所有之前拥有相同 key 的消息被移除（包括拥有 key 相同的新消息）。但是删除标记比较特殊，它将在一定周期后被从日志中删除来释放空间，这个时间点被称为 "delete retention point"。

压缩是在后台通过定期重新复制日志段来完成的。清洗不会阻塞读，可以限流 I/O 吞吐量（是可配置），以避免影响生产者和消费者。实际压缩处理日志看起来像这样：

<div align="left">
    <img src="https://github.com/lazecoding/Note/blob/main/images/kafka/压缩处理日志示意图.png" width="600px">
</div>

日志压缩提供的保障：

- 任何滞留在日志 head 中的所有消费者能看到写入的所有消息；这些消息都是有序的offset。 topic 使用 `min.compaction.lag.ms` 来保障消息写入之前必须经过的最小时间长度，才能被压缩。 这限制了一条消息在 Log Head 中的最短存在时间。
- 消息始终保持有序。压缩永远不会重新排序消息，只是删除了一些。
- 消息的 Offset 永远不会变更。这是消息在日志中的永久标志。
- 任何从头开始处理日志的 Consumer 至少会拿到每个 key 的最终状态。另外，只要 Consumer 在小于 Topic 的 `delete.retention.ms` 设置（默认 24 小时）的时间段内到达 Log Head，将会看到所有删除记录的所有删除标记。换句话说，因为移除删除标记和读取是同时发生的，Consumer 可能会因为落后超过 `delete.retention.ms` 而导致错过删除标记。

##### 日志压缩的细节

日志压缩由 Log Cleaner 执行，Log Cleaner 是一个后台线程池，它会 recopy 日志段文件，移除那些 key 存在于 Log Head 中的记录。每个压缩线程工作的步骤如下：

- 选择 Log Head 与 Log Tail 比率最高的日志。
- 在 Head Log 中为每个 key 最后 offset 创建一个简单概要。
- 从日志的开始到结束，删除那些在日志中最新出现的 key 的旧值。新的、干净的日志会被立即提交到日志中，所以只需要一个额外的日志段空间（不是日志的完整副本）。
- 日志 Head 的概念本质上是一个空间密集的 hash 表，每个条目使用 24 个字节。所以如果有 8G 的整理缓冲区，则能迭代处理大约 336G 的 Log Head （假设消息大小为 1k）。

##### 配置 Log Cleaner

Log cleaner 默认是启动的，也将启动 Cleaner 线程池：

```C
log.cleaner.enable=true
```

你也可以针对特定 topic 启用 Log cleaner：

```C
log.cleanup.policy=compact
```

配置消息在被清理前的最小保留时间，这可以预防消息在一个最小消息时间绝不会被压缩。如果不设置，除了最新的段，其他所有的段都是可以压缩的，即：当前正在写入的那个。即使其所有消息都比最小压缩时间滞后更长，正在写入的段也不会被压缩。

```C
log.cleaner.min.compaction.lag.ms
```

配置消息在被清理前的最小保留时间最大保留时间，防止低生产速率的日志在无限制的时间内不适合压缩。

```C
log.cleaner.max.compaction.lag.ms
```

### 磁盘存储

Kafka 依赖于文件系统(更底层地来说就是磁盘)来存储和缓存消息。

在印象中，磁盘的读写速度处于一个比较尴尬的位置，这不禁让我们怀疑 Kafka 采用这种持久化形式能否提供有竞争力的性能。然而，事实上磁盘可以比我们预想的要快，也可能比我们预想的要慢，这完全取决于我们如何使用它。

有关测试结果表明，一个由 6 块 7200r/min 的 RAID-5 阵列组成的磁盘簇的线性(顺序)写入速度可以达到 600MB/s，而随机写入速度只有 100KB/s，两者性能相差 6000 倍。操作系统可以针对线性读写做深层次的优化，比如预读(read-ahead，提前将一个比较大的磁盘块读入内存)和后写(write behind，将很多小的逻辑写操作合并起来组成一个大的物理写操作)技术。顺序写盘的速度不仅比随机写盘的速度快，而且也比随机写内存的速度快，如图所示。

<div align="left">
    <img src="https://github.com/lazecoding/Note/blob/main/images/kafka/内存和磁盘读写速度比较.png" width="600px">
</div>

Kafka 在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息，这种方式属于典型的顺序写盘的操作，所以就算 Kafka 使用磁盘作为存储介质，它所能承载的吞吐量也不容小觑。

#### 页缓存

页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘I/O的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问。

- 当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页(page)是否在页缓存(pagecache)中，如果存在(命中)则直接返回数据，从而避免了对物理磁盘的 I/0 操作；如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，之后再将数据返回给进程。
- 如果一个进程需要将数据写入磁盘，那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，最后将数据写入对应的页。被修改过后的页也就变成了脏页，操作系统会在合适的时间把脏页中的数据写入磁盘，以保持数据的一致性。

对一个进程而言，它会在进程内部缓存处理所需的数据，然而这些数据有可能还缓存在操作系统的页缓存中，因此同一份数据有可能被缓存了两次。并且，除非使用 Direct I/O 的方式，否则页缓存很难被禁止。此外，用过 Java 的人一般都知道两点事实：对象的内存开销非常大，通常会是真实数据大小的几倍甚至更多，空间使用率低下；Java的垃圾回收会随着堆内数据的增多而变得越来越慢。

基于这些因素，使用文件系统并依赖于页缓存的做法明显要优于维护一个进程内缓存或其他结构，至少我们可以省去了一份进程内部的缓存消耗，同时还可以通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间。如此，我们可以在 32GB 的机器上使用 28GB 至 30GB 的内存而不用担心 GC 所带来的性能问题。此外，即使 Kafka 服务重启，页缓存还是会保持有效，然而进程内的缓存却需要重建。这样也极大地简化了代码逻辑，因为维护页缓存和文件之间的一致性交由操作系统来负责，这样会比进程内维护更加安全有效。

Kafka 中大量使用了页缓存，这是 Kafka 实现高吞吐的重要因素之一。

消息都是先被写入页缓存，然后由操作系统负责具体的刷盘任务的。Kafka 提供了同步刷盘和间断性强制刷盘(fsync)的功能，这些功能可以通过 `log.flush.interval.messages`、`log.flush.interval.ms` 等参数来控制。

Linux 系统会使用磁盘的一部分作为 swap 分区，这样可以进行进程的调度：把当前非活跃的进程调入 swap 分区，以此把内存空出来让给活跃的进程。对大量使用系统页缓存的 Kafka 而言，应当尽量避免这种内存的交换，否则会对它各方面的性能产生很大的负面影响。

#### 零拷贝

Katka 使用零拷贝(Zero-Copy)技术来进一步提升性能。零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。

更多 [零拷贝](https://github.com/lazecoding/Note/blob/main/note/articles/java/NIO.md#零拷贝
) 相关内容，点击查看。